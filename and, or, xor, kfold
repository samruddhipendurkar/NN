import numpy as np 

import pandas as pd 

df = pd.read_csv( 

    'https://raw.githubusercontent.com/infiniaclub/NeuralNetworkDataset/main/sonar%20dataset.csv').values 

print((f"Dataset :\n{df}")) 

Dataset : 

[[ 2.7810836   2.550537    0.        ] 

[ 1.46548937  2.36212508  0.        ] 

[ 3.39656169  4.40029353  0.        ] 

[ 1.38807019  1.85022032  0.        ] 

[ 3.06407232  3.00530597  0.        ] 

[ 7.62753121  2.75926224  1.        ] 

[ 5.33244125  2.08862677  1.        ] 

[ 6.92259672  1.77106367  1.        ] 

[ 8.67541865 -0.24206865  1.        ] 

[ 7.67375647  3.50856301  1.        ]] 

 

def predict(row,weights): 

  activation=weights[0] 

  for i in range(len(row)-1): 

    activation += weights[i+1]*row[i] 

  return 1 if activation >=0 else 0 

correct_predictions = 0 

for row in df: 

  prediction=predict(row,weights) 

  if prediction == row[-1]: 

        correct_predictions += 1 

  print(f"Actual {round(row[-1])} Predicted :{prediction}") 

accuracy = (correct_predictions / len(df))*100 

print(f"Accuracy is : {accuracy}%") 

 

 

Ouput: 

 

Actual 0 Predicted :0 

Actual 0 Predicted :0 

Actual 0 Predicted :0 

Actual 0 Predicted :0 

Actual 0 Predicted :0 

Actual 1 Predicted :1 

Actual 1 Predicted :1 

Actual 1 Predicted :1 

Actual 1 Predicted :1 

Actual 1 Predicted :1 

Accuracy is : 100.0% 

 

def predict(row,weights): 

  activation=weights[0] 

  for i in range(len(row)-1): 

    activation +=weights[i+1]*row[i] 

  return 1 if activation >=0 else 0 

  

def training_data(train_data,learning_rate,n_epoch): 

  weights=[0 for i in range(len(train_data[0]))] 

  for epoch in range(n_epoch): 

    sum_err=0 

    for row in train_data: 

      prediction=predict(row,weights) 

      err=row[-1]-prediction 

      sum_err+=err**2 

      weights[0] = weights[0] + learning_rate*err 

      for i in range(len(row)-1): 

        weights[i+1] =weights[i+1]+learning_rate*err*row[i] 

    print(f">epoch:{epoch},Learning_rate :{learning_rate},MSE:{sum_err}") 

  return weights 

  

learning_rate=0.1 

n_epoch=5 

weights=training_data(df,learning_rate,n_epoch) 

print(f"Computed Bias {round(weights[0],3)} , Computed Weights{weights[1:]}") 

 

 

Output:  

 

>epoch:0,Learning_rate :0.1,MSE:2.0 

>epoch:1,Learning_rate :0.1,MSE:1.0 

>epoch:2,Learning_rate :0.1,MSE:0.0 

>epoch:3,Learning_rate :0.1,MSE:0.0 

>epoch:4,Learning_rate :0.1,MSE:0.0 

Computed Bias -0.1 , Computed Weights[0.20653640140000007, -0.23418117710000003] 

 

 

 

correct_predictions = 0 

for row in df: 

  prediction=predict(row,weights) 

  if prediction == row[-1]: 

        correct_predictions += 1 

  print(f"Actual {round(row[-1])} Predicted :{prediction}") 

accuracy = (correct_predictions / len(df))*100 

print(f"Accuracy is : {accuracy}%") 

 

 

Output:  

 

Actual 0 Predicted :0 

Actual 0 Predicted :0 

Actual 0 Predicted :0 

Actual 0 Predicted :0 

Actual 0 Predicted :0 

Actual 1 Predicted :1 

Actual 1 Predicted :1 

Actual 1 Predicted :1 

Actual 1 Predicted :1 

Actual 1 Predicted :1 

Accuracy is : 100.0% 

 

 

 

 

AND GATE 

 

 

logical_and_dataset = pd.read_csv("https://raw.githubusercontent.com/infiniaclub/NeuralNetworkDataset/main/logical_and.csv").values 

learning_rate = 0.01  ## 1% Learning Rate 

n_epoch = 7    ## Change n_epoch or learning_rate to see effect on prediction 

logical_and_dataset 

 

array([[1, 1, 1], 

       [1, 0, 0], 

       [0, 1, 0], 

       [0, 0, 0]]) 

 

def training_weights(train_data,learning_rate,n_epoch): 

  weights=[0 for i in range(len(train_data[0]))] 

  for epoch in range(n_epoch): 

    sum_err=0 

    for row in train_data: 

      prediction=predict(row,weights) 

      err=row[-1]-prediction 

      sum_err +=err**2 

      weights[0] += learning_rate*err 

      for i in range(len(row)-1): 

        weights[i+1] += learning_rate*err*row[i] 

    print(f">epoch ={epoch}, learning_rate={learning_rate},MSE={sum_err}") 

  return weights 

  

weights = training_weights(logical_and_dataset, learning_rate, n_epoch) 

print(f"\n Computed Bias : {round(weights[0],3)} \n Computed Weights_i: {weights[1:]} \n") 

 

 

 

 

Output: 

 

>epoch =0, learning_rate=0.01,MSE=1 

>epoch =1, learning_rate=0.01,MSE=3 

>epoch =2, learning_rate=0.01,MSE=2 

>epoch =3, learning_rate=0.01,MSE=2 

>epoch =4, learning_rate=0.01,MSE=3 

>epoch =5, learning_rate=0.01,MSE=2 

>epoch =6, learning_rate=0.01,MSE=2 

  

 

Computed Bias : -0.03  

Computed Weights_i: [0.01, 0.02]  

  

for row in logical_and_dataset: 

prediction = predict(row, weights) 

print(f"Actual: {round(row[-1])}  Predicted: {round(prediction)}") 

 

 

 

Output: 

 

Actual: 1  Predicted: 1 

Actual: 0  Predicted: 0 

Actual: 0  Predicted: 0 

Actual: 0  Predicted: 0 

 

 

 

 

OR GATE 

 

 

inputs = np.array([[0,0,0],[0,1,1],[1,0,1],[1,1,1]]) 

Inputs 

 

array([[0, 0, 0], 

       [0, 1, 1], 

       [1, 0, 1], 

       [1, 1, 1]]) 

 

def pre(r,w): 

  act=w[0] 

  for i in range(len(r)-1): 

    act +=w[i+1]*r[i] 

  return 1 if act>=0 else 0 

 

def td(train,lr,ep): 

  w=[0 for i in range(len(train)-1)] 

  for ec in range(ep): 

    sr=0 

    for r in train: 

      pr=pre(r,w) 

      er=r[-1]-pr 

      sr += er**2 

      w[0] +=lr*er 

      for i in range(len(r)-1): 

        w[i+1] +=lr*er*r[i] 

    print(f"> epoch={ec},Learning={lr},MSE={sr}") 

  return w 

  

lr=0.01 

ep=5 

w=td(inputs,lr,ep) 

 

Output:  

 

> epoch=0,Learning=0.01,MSE=2 

> epoch=1,Learning=0.01,MSE=2 

> epoch=2,Learning=0.01,MSE=1 

> epoch=3,Learning=0.01,MSE=0 

> epoch=4,Learning=0.01,MSE=0 

 

 

for r in inputs: 

  pr=pre(r,w) 

  print(f"Actual {r[-1]} Prediction:{pr}") 

 

 

 

Output: 

 

Actual 0 Prediction:0 

Actual 1 Prediction:1 

Actual 1 Prediction:1 

Actual 1 Prediction:1 

 

 

 

 

XOR GATE 

 

 

inputs = np.array([[0,0,0],[0,1,1],[1,0,1],[1,1,0]]) 

  

def pre(r,w): 

  act=w[0] 

  for i in range(len(r)-1): 

    act +=w[i+1]*r[i] 

  return 1 if act>=0 else 0 

 

def td(train,lr,ep): 

  w=[0 for i in range(len(train)-1)] 

  for ec in range(ep): 

    sr=0 

    for r in train: 

      pr=pre(r,w) 

     er=r[-1]-pr 

      sr += er**2 

      w[0] +=lr*er 

      for i in range(len(r)-1): 

        w[i+1] +=lr*er*r[i] 

    print(f"> epoch={ec},Learning={lr},MSE={sr}") 

  return w 

  

lr=0.01 

ep=5 

w=td(inputs,lr,ep) 

 

 

Output:  

 

> epoch=0,Learning=0.01,MSE=3 

> epoch=1,Learning=0.01,MSE=3 

> epoch=2,Learning=0.01,MSE=4 

> epoch=3,Learning=0.01,MSE=4 

> epoch=4,Learning=0.01,MSE=4 

 

 

for r in inputs: 

  pr=pre(r,w) 

  print(f"Actual {r[-1]} Prediction:{pr}") 

 

 

Output: 

 

Actual 0 Prediction:1 

Actual 1 Prediction:1 

Actual 1 Prediction:0 

Actual 0 Prediction:0 

 

 

 

K-FOLD  

 

from numpy import mean 

from sklearn.datasets import make_classification 

from sklearn.model_selection import LeaveOneOut 

from sklearn.model_selection import KFold 

from sklearn.model_selection import cross_val_score 

from sklearn.linear_model import LogisticRegression 

from matplotlib import pyplot 

  

# create the dataset 

def get_dataset(n_samples=100): 

X, y = make_classification(n_samples=n_samples, n_features=20, n_informative=15, n_redundant=5, random_state=1) 

return X, y 

  

# retrieve the model to be evaluate 

def get_model(): 

model = LogisticRegression() 

return model 

  

# evaluate the model using a given test condition 

def evaluate_model(cv): 

# get the dataset 

X, y = get_dataset() 

# get the model 

model = get_model() 

# evaluate the model 

scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1) 

# return scores 

return mean(scores), scores.min(), scores.max() 

  

# calculate the ideal test condition 

ideal, _, _ = evaluate_model(LeaveOneOut()) 

print('Ideal: %.3f' % ideal) 

# define folds to test 

folds = range(2,31) 

# record mean and min/max of each set of results 

means, mins, maxs = list(),list(),list() 

# evaluate each k value 

for k in folds: 

# define the test condition 

cv = KFold(n_splits=k, shuffle=True, random_state=1) 

# evaluate k value 

k_mean, k_min, k_max = evaluate_model(cv) 

# report performance 

print('> folds=%d, accuracy=%.3f (%.3f,%.3f)' % (k, k_mean, k_min, k_max)) 

# store mean accuracy 

means.append(k_mean) 

# store min and max relative to the mean 

mins.append(k_mean - k_min) 

maxs.append(k_max - k_mean) 

# line plot of k mean values with min/max error bars 

pyplot.errorbar(folds, means, yerr=[mins, maxs], fmt='o') 

# plot the ideal case in a separate color 

pyplot.plot(folds, [ideal for _ in range(len(folds))], color='r') 

# show the plot 

pyplot.show()
