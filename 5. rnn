from keras.preprocessing import sequence
from keras.models import Sequential
from keras.layers import Dense, Embedding
from keras.layers import LSTM
# Using Recurrent Neural Networks (LSTM) to train on IMDB Dataset and perform Review Analysis (Checking whether review is positive or Negative
from keras.datasets import imdb
(x_train, y_train),(x_test, y_test) = imdb.load_data(num_words=5000)
x_train = sequence.pad_sequences(x_train, maxlen=80)
x_test = sequence.pad_sequences(x_test, maxlen=80)
#creating model
model = Sequential()
model.add(Embedding(5000,128))
model.add(LSTM(128,activation='tanh',recurrent_activation="sigmoid"))
model.add(Dense(1,activation="sigmoid"))
model.compile(loss="binary_crossentropy",optimizer='adam',metrics=['accuracy'])
#training
lstm = model.fit(x_train,y_train,batch_size=32,epochs=3,validation_data=(x_test,y_test),shuffle=True,verbose=1)
Epoch 1/3
782/782 ━━━━━━━━━━━━━━━━━━━━ 152s 192ms/step - accuracy: 0.7208 - loss: 0.5229 - val_accuracy: 0.8278 - val_loss: 0.3818
Epoch 2/3
782/782 ━━━━━━━━━━━━━━━━━━━━ 149s 191ms/step - accuracy: 0.8651 - loss: 0.3136 - val_accuracy: 0.8414 - val_loss: 0.3564
Epoch 3/3
782/782 ━━━━━━━━━━━━━━━━━━━━ 202s 191ms/step - accuracy: 0.8999 - loss: 0.2402 - val_accuracy: 0.8348 - val_loss: 0.3852
Model: "sequential_3"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓
┃ Layer (type) ┃ Output Shape ┃ Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩
│ embedding_3 (Embedding) │ (None, 80, 128) │ 640,000 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ lstm_3 (LSTM) │ (None, 128) │ 131,584 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dense_3 (Dense) │ (None, 1) │ 129 │
└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘
 Total params: 2,315,141 (8.83 MB)
 Trainable params: 771,713 (2.94 MB)
 Non-trainable params: 0 (0.00 B)
Optimizer params: 1 543 428 (5 89 MB)
model.summary()
op = model.predict(x_test)
op
782/782 ━━━━━━━━━━━━━━━━━━━━ 36s 46ms/step
array([[0.26074958],
 [0.99686515],
 [0.71205527],
 ...,
 [0.20223275],
 [0.20616357],
 [0.9803803 ]], dtype=float32)
8/25/24, 10:31 PM Sentiment_Analysis_using_RNN.ipynb - Colab
https://colab.research.google.com/drive/11i5T9JL7KLGn6CvyU-cQfDJNysGBvJo1#scrollTo=1ULOcKtRNLy1&printMode=true 1/2
#Using test data to check the predicted values
from random import randint
arr_ind=randint(0,24999)
index=imdb.get_word_index()
reverse_index = dict([(value, key) for (key, value) in index.items()])
decoded = " ".join([reverse_index.get(i - 3, "#") for i in x_test[arr_ind]])
arr=[]
for i in op:
if(i<0.5):
arr.append("Negative")
else:
arr.append("Positive")
print("Sentence:",decoded),
print("Review:",arr[arr_ind])
print("Predicted Value:",op[arr_ind][0])
print("Expected Value:",y_test[arr_ind])
Sentence: for character br br from a marketing # i was left asking myself who in the world were they # at the # thriller plot line is wa
Review: Negative
Predicted Value: 0.1605518
Expected Value: 0
8/25/24, 10:31 PM Sentiment_Analysis_using_RNN.ipynb - Colab
https://colab.research.google.com/drive/11i5T9JL7KLGn6CvyU-cQfDJNysGBvJo1#scrollTo=1ULOcKtRNLy1&printMode=true 2/2
